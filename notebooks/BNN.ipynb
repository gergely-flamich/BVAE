{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/scratch/gf332/Misc/BVAE/code')\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from bnn import MnistBNN\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tfd = tfp.distributions\n",
    "\n",
    "data_dir = \"/scratch/gf332/Misc/datasets/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set CPU as available physical device\n",
    "tf.config.experimental.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tfds.load(\"mnist\", data_dir=data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_dir = \"/scratch/gf332/Misc/bnn_experiments/bnn/adaptive_sghmc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored model from /scratch/gf332/Misc/bnn_experiments/bnn/adaptive_sghmc/ckpt-833\n"
     ]
    }
   ],
   "source": [
    "model = MnistBNN()\n",
    "model.build(input_shape=(1, 28, 28, 1))\n",
    "\n",
    "ckpt = tf.train.Checkpoint(model=model)\n",
    "\n",
    "manager = tf.train.CheckpointManager(ckpt, model_save_dir, max_to_keep=3)\n",
    "\n",
    "# Restore previous session\n",
    "ckpt.restore(manager.latest_checkpoint)#.expect_partial()\n",
    "if manager.latest_checkpoint:\n",
    "    print(f\"Restored model from {manager.latest_checkpoint}\")\n",
    "else:\n",
    "    print(\"Initializing model from scratch.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[3.3781141e-06 1.2709611e-03 1.1710143e-04 7.7699521e-03 5.1132739e-02\n",
      "  4.9366145e-03 1.9189704e-04 3.5108395e-03 4.1041333e-02 8.9002526e-01]], shape=(1, 10), dtype=float32)\n",
      "Actual:  9\n",
      "Prediction: 9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_ds = mnist['test']\n",
    "test_ds = test_ds.map(lambda x: (tf.cast(x[\"image\"], tf.float32) / 255., x[\"label\"])).shuffle(300)\n",
    "\n",
    "for im, label in test_ds.batch(1).take(1):\n",
    "    \n",
    "    plt.imshow(im[0, ..., 0])\n",
    "    \n",
    "    probs = model(im)\n",
    "    \n",
    "    print(probs)\n",
    "    \n",
    "    print(\"Actual: \", label[0].numpy())\n",
    "    print(\"Prediction:\", tf.argmax(probs, axis=1)[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = 0.\n",
    "total_size = 0.\n",
    "\n",
    "batch_size = 500\n",
    "\n",
    "for im, label in test_ds.batch(batch_size).take(1):\n",
    "    \n",
    "    probs = model(im)\n",
    "    \n",
    "    test_accuracy += tf.reduce_sum(tf.cast(tf.argmax(probs, axis=1) == label, tf.float32))\n",
    "    \n",
    "    total_size += tf.cast(label.shape[0], tf.float32)\n",
    "    \n",
    "test_accuracy = test_accuracy / total_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.922>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
